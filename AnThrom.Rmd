---
output:
  html_notebook:
    number_sections: no
    theme: default
    toc: yes
    toc_float: yes
  html_document:
    df_print: paged
    toc: yes
---
#**AnThroM**
**testing the relation between Theory-of-Mind network activation and dispositional anthropomorphism**  
by *Ruud Hortensius and (University of Glasgow) - June 2019 - ...*

# 1. Details {.tabset}

## 1.1 Data 

Data of the Theory-of-Mind functional localiser and Individual Differences in Anthropomorphism Questionnaire are from five different studies.
  
 Dataset_1: Bangor Imaging Unit; EMBOTS; *n*=28; full dataset and publication: [Cross...Hortensius (2019) PTRB](https://royalsocietypublishing.org/doi/10.1098/rstb.2018.0034)  
 Dataset_2: Centre for Cognitive NeuroImaging; SHAREDBOTS; *n*=35 (including 2 pilot scans) publication: Hortensius & Cross, in preparation
 Dataset_3: Centre for Cognitive NeuroImaging; Two studies with the same parameters: *n*=22. Social_Gradient_1; *n*=10 (pilot experiment) and BOLDlight; *n*=12.
 Dataset_4: Centre for Cognitive NeuroImaging; GAMEBOTS; *n*

## 1.2 Neuroimaging procedure
 
 All participants completed a Theory-of-Mind localiser ([Jacoby et al., 2016](https://www.sciencedirect.com/science/article/pii/S1053811915010472); [Richardson et al. 2018](https://www.nature.com/articles/s41467-018-03399-2)) and an anatomical scan either in the same session or in two seperate sessions. During the localiser participants passively viewed a short 5.6 min animated film ([Partly Cloudy](https://www.pixar.com/partly-cloudy#partly-cloudy-1)). This movie includes scenes depicting pain (e.g. an alligator biting the main character) and events that trigger mentalizing (e.g. the main character revealing its intention). At the end of each experiment participants completed the Individual Differences in Anthropomorphism Questionnaire (IDAQ) ([Waytz et al., 2010](https://journals.sagepub.com/doi/full/10.1177/1745691610369336)). 
 
- BOLD:
 Dataset_1: 3x3x3.5 voxels, 32 slices, repetition time = 2s, echo time = 30ms  
 Dataset_2: 3mm isotropic, 37 slices, TR = 2s, TE = 30ms  
 Dataset_3: 2mm isotropic, 68 slices, TR = 2s, TE = 27ms  
 Dataset_4:
 
- T1W:
 Dataset_1: 1mm isotropic resolution, TR = 12ms, TE = 3.5ms  
 Dataset_2 - 4: 1mm isotropic resolution, TR = 2.3s, TE = 29.6ms (ADNI)  
 
## 1.3 To do
- get Dicoms, create BIDS dataset, use sub-101, sub-201, sub-301 etc...  
- remove Dicoms after BIDS dataset creation  
- Deface dataset  
- run MRIQC
- run fMRIprep  
- fROI  

# 2. BIDS dataset {.tabset}

## 2.1 Creating the BIDS dataset
For this you need HeuDiConv [Heuristic DICOM Converter](https://github.com/nipy/heudicon).  
Based on the tutorial by [Franklin Feingold](http://reproducibility.stanford.edu/bids-tutorial-series-part-2a/).

Dowload the latest version of Heudiconv

```{bash}
docker pull nipy/heudiconv:latest
```

Create the info file
```{bash}
docker run --rm -it -v /Volumes/Project0255/:/base nipy/heudiconv:latest -d /base/dataset_3/sourcedata/sub-{subject}/*.IMA -o /base/code -f convertall -s 301 -c none --overwrite
```

Get the info file
```{bash}
cp /Volumes/Project0255/code/.heudiconv/301/info/dicominfo.tsv /Volumes/Project0255/code
```

## 2.3 Create the heuristic file
Create the following python file and save it in the code folder (don't run the code).

```{python}
import os
def create_key(template, outtype=('nii.gz',), annotation_classes=None):
    if template is None or not template:
        raise ValueError('Template must be a valid format string')
    return template, outtype, annotation_classes
def infotodict(seqinfo):
    """Heuristic evaluator for determining which runs belong where
    allowed template fields - follow python string module:
    item: index within category
    subject: participant id
    seqitem: run number during scanning
    subindex: sub index within group
    """
    t1w = create_key('sub-{subject}/anat/sub-{subject}_T1w')
    func_movie = create_key('sub-{subject}/func/sub-{subject}_task-movie_bold')
    fmap_phase = create_key('sub-{subject}/fmap/sub-{subject}_phasediff')
    fmap_magnitude = create_key('sub-{subject}/fmap/sub-{subject}_magnitude')
    
    info = {t1w: [], func_movie: [], fmap_phase: [], fmap_magnitude: []} 
    
    for idx, s in enumerate(seqinfo):
        if ('t1_mpr_ns_sag_iso_ADNI_32ch' in s.protocol_name):
            info[t1w].append(s.series_id)
        if ('t1_mpr_ns_sag_P2_ADNI_32ch' in s.protocol_name):
            info[t1w].append(s.series_id)    
        if (s.dim4 == 175) and ('FMRI_MB2_p2_2MMISO_TR2_movie' in s.protocol_name):
            info[func_movie].append(s.series_id)          
        if (s.dim3 == 92) and ('gre_field_mapping_AAH' in s.protocol_name):
            info[fmap_magnitude].append(s.series_id)      
        if (s.dim3 == 46) and ('gre_field_mapping_AAH' in s.protocol_name):
            info[fmap_phase].append(s.series_id)               
    return info
```

There are three functional tasks (func_task, func_tom, and func_ppn) and one anatomical (t1w). Create a heuristic to automatically convert the files:

For example, func_tom has 175 volumes, with 'ep2d_ToM_Loc_boldTR2' as name.

Use the heuristic file to convert the .IMA (dicom) files to .nii.gz (nifti) and create .json files 

```{bash}
docker run --rm -it -v /Volumes/Project0255/:/base nipy/heudiconv:latest -d /base/dataset_3/sourcedata/sub-{subject}/*.IMA -o /base/dataset_3 -f /base/code/heuristic_dataset3.py -s 301 -c dcm2niix -b --overwrite
```

## 2.4 Anonymize the data
Data from experiment 1 need to be defaced using [Pydeface](https://github.com/poldracklab/pydeface).

```{bash}
#!/bin/bash

set -e 
####For loop that defaces the MRI per subject and replaces the old MRI with the new defaced MRI
rootfolder=/Volumes/Project0255/dataset_3

for subj in 301; do
	echo "Defacing participant $subj"
pydeface ${rootfolder}/sub-${subj}/anat/sub-${subj}_T1w.nii.gz
rm -f ${rootfolder}/sub-${subj}/anat/sub-${subj}_T1w.nii.gz
mv ${rootfolder}/sub-${subj}/anat/sub-${subj}_T1w_defaced.nii.gz ${rootfolder}/sub-${subj}/anat/sub-${subj}_T1w.nii.gz 
done
```

## 2.5 BIDS validation

Use the BIDS-Validator to check if the dataset is BIDS compliant.

```{bash}
docker run -ti --rm -v /Volumes/Project0255/dataset_3:/data:ro bids/validator /data
```

# 3. Theory-of-Mind event protocols {.tabset}

Create tsv file for functional localiser

Event coding (in s;  10s of fixation before movie starts; accounting for hemodynamic lag) is based on Richardson et al. 2018 - reverse correlation analyses. 
```{r}
PartlyCloudy <- data.frame(onset = c(86, 98, 120, 176, 238, 252, 300, 70, 92, 106, 136, 194, 210, 228, 262, 312), #create the events (same for every sub)
                           duration = c(4, 6, 4, 16, 6, 8, 6, 4, 2, 4, 10, 4, 12, 6, 6, 4),
                           trial_type = c(rep("mental",7), rep("pain",9)))

#dataset_1
for (sub in 3:28){ #note: localisers for sub-01 and sub-02 are in ses-02
  sub <- ifelse(sub < 10, paste0("0", sub), sub)
  filename = paste("/Volumes/Project0246/dataset_1/sub-", sub, "/ses-01/func/sub-", sub, "_ses-01_task-tom_events.tsv", sep ="")
write.table(PartlyCloudy, file = filename, sep="\t", row.names = FALSE, quote = FALSE)
}
#dataset_2
for (sub in 1:33){ #note: ppn22 ToM is in ses-00
  sub <- ifelse(sub < 10, paste0("0", sub), sub)
  filename = paste("/Volumes/Project0246/dataset_2/sub-", sub, "/ses-01/func/sub-", sub, "_ses-01_task-tom_events.tsv", sep ="")
write.table(PartlyCloudy, file = filename, sep="\t", row.names = FALSE, quote = FALSE)
}
#dataset_3
for (sub in 1:10){ 
  sub <- ifelse(sub < 10, paste0("0", sub), sub)
  filename = paste("/Volumes/Project0246/dataset_3/sub-", sub, "/ses-01/func/sub-", sub, "_ses-01_task-tom_events.tsv", sep ="")
write.table(PartlyCloudy, file = filename, sep="\t", row.names = FALSE, quote = FALSE)
}

```

# 4. Preprocessing {.tabset}

## 4.1 MRIQC 
MRIQC is a docker tool to do quality control of the data. More info [here](https://poldracklab.github.io/mriqc/).

MRIQC 0.14.2 was used:

```{bash}
docker run -it --rm -v /Volumes/Project0255/dataset_3/:/data:ro -v /Volumes/Project0255/dataset_3/derivatives/mriqc:/out poldracklab/mriqc:0.14.2 /data /out participant --participant-label 301 -m T1w bold --ica --fft-spikes-detector
```

Run it seperately for the datasets. Change participant to group to create the group reports.

```{bash}
docker run -it --rm -v /Volumes/Project0255/dataset_3/:/data:ro -v /Volumes/Project0255/dataset_3/derivatives/mriqc:/out poldracklab/mriqc:0.14.2 /data /out group
```


## 4.2 fMRIprep 
fMRIprep is a docker tool for preprocessing of the fMRI data. More info [here](https://fmriprep.readthedocs.io/en/stable/#)

fMRIprep version 1.5.0 was used on the grid.

If you run into memory problems you can use --skip_bids_validation; skipped the --write-graph flag to save space

--use-syn-sdc for dataset_1 and dataset_2

If run on the lab iMac, with 50GB of docker memory, and with --fs-no-reconall (no segmentation), it takes about 20 min per participant.

```{bash}
/Users/soba/.local/bin/fmriprep-docker /Volumes/Project0255/dataset_3/ /Volumes/Project0255/dataset_3/derivatives participant --participant-label 301  --fs-license-file /Users/soba/license.txt --fs-no-reconall 
```

Singularity run:

```{bash}
singularity run --cleanenv /analyse/Project0246/my_images/fmriprep-1.3.2.simg /Volumes/Project0246/dataset_1/ //Volumes/Project0246/dataset_1/derivatives participant --participant-label sub-01 sub-02 sub-03 sub-04 sub-05 --fs-license-file /analyse/Project0246/my_images/license.txt --skip_bids_validation --fs-no-reconall --use-syn-sdc
```

Run it seperately for the datasets.
<<<<<<< HEAD
=======

# 4. IDAQ {.tabset}

## Calculation of individual scores

# 5. Results {.tabset}

## Comparison across studies
