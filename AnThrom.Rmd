---
output:
  html_notebook:
    number_sections: no
    theme: default
    toc: yes
    toc_float: yes
  html_document:
    df_print: paged
    toc: yes
---
#**AnThroM**
**testing the relation between Theory-of-Mind network activation and dispositional anthropomorphism**  
by *Ruud Hortensius (University of Glasgow) - June 2019 - ...*

# 1. Details {.tabset}

## 1.1 Data
  
 Exp_1: Bangor Imaging Unit; EMBOTS; *n*=28; publications [Cross...Hortensius (2019) PTRB](https://royalsocietypublishing.org/doi/10.1098/rstb.2018.0034)  
 Exp_2: Centre for Cognitive NeuroImaging; SHAREDBOTS; *n*=33  
 Exp_3: Centre for Cognitive NeuroImaging; Social_Gradient_1; *n*=10  
 Exp_4: Centre for Cognitive NeuroImaging; BOLDlight; *n*=12 (ongoing)  

## 1.2 Neuroimaging procedure
 
 All participants completed a Theory-of-Mind localiser ([Jacoby et al., 2016](https://www.sciencedirect.com/science/article/pii/S1053811915010472); [Richardson et al. 2018](https://www.nature.com/articles/s41467-018-03399-2)) and an anatomical scan either in the same session or in two seperate sessions. During the localiser participants passively viewed a short 5.6 min animated film ([Partly Cloudy](https://www.pixar.com/partly-cloudy#partly-cloudy-1)). This movie includes scenes depicting pain (e.g. an alligator biting the main character) and events that trigger mentalizing (e.g. the main character revealing its intention). At the end of each experiment participants completed the Individual Differences in Anthropomorphism Questionnaire (IDAQ) ([Waytz et al., 2010](https://journals.sagepub.com/doi/full/10.1177/1745691610369336)). 
 
- BOLD:
 Exp 1: 3x3x3.5 voxels, 32 slices, repetition time = 2s, echo time = 30ms  
 Exp 2: 3mm isotropic, 37 slices, TR = 2s, TE = 30ms  
 Exp 3 - 4: 2mm isotropic, 68 slices, TR = 2s, TE = 27ms  
 
- T1W:
 Exp 1: 1mm isotropic resolution, TR = 12ms, TE = 3.5ms  
 Exp 2 - 4: 1mm isotropic resolution, TR = 2.3s, TE = 29.6ms (ADNI)  

# 2. BIDS dataset {.tabset}

## 2.1 Creating the BIDS dataset

Exp 1: already Nifti so did it manually
Exp 2 - 4: were already in BIDS format, only kept the relevant scans (T1w ses-01 and tom-bold)

## 2.2 Anonymize the data
Data from experiment 1 need to be defaced using [Pydeface](https://github.com/poldracklab/pydeface).

Copy the following code into the terminal after typing
```
bash
```
Loop that defaces the MRI per subject and replaces the old MRI with the new defaced MRI

```
#!/bin/bash

set -e 
####For loop that defaces the MRI per subject and replaces the old MRI with the new defaced MRI
rootfolder=/Volumes/Project0245/data_exp1

for subj in 01 03 07 12 13 17 18 19 22 23 24 28; do
	echo "Defacing participant $subj"
for session in 01;do
pydeface ${rootfolder}/sub-${subj}/ses-${session}/anat/sub-${subj}_ses-${session}_T1w.nii
rm -f ${rootfolder}/sub-${subj}/ses-${session}/anat/sub-${subj}_ses-${session}_T1w.nii
mv ${rootfolder}/sub-${subj}/ses-${session}/anat/sub-${subj}_ses-${session}_T1w_defaced.nii ${rootfolder}/sub-${subj}/ses-${session}/anat/sub-${subj}_ses-${session}_T1w.nii 
done
done
```
and for the subjects that had the T1w in the ses-02 replace the three lines with:
```
for subj in 02 04 05 06 08 09 10 11 15 16 20 21 25 26 27; do
	echo "Defacing participant $subj"
for session in 02;do
```
## 2.2 Compressed the data
Use gzip to compress the data. Careful not to leave any sensitive information in the file (use --no-name)
```
#!/bin/bash

set -e 
####For loop that defaces the MRI per subject and replaces the old MRI with the new defaced MRI
rootfolder=/Volumes/Project0245/data_exp1

for subj in 01 03 07 12 13 17 18 19 22 23 24 28; do
	echo "Zipping participant $subj"
for session in 01;do
gzip --no-name ${rootfolder}/sub-${subj}/ses-${session}/anat/sub-${subj}_ses-${session}_T1w.nii
done
done
```
and for the subjects that had the T1w in the ses-02 replace the three lines with:
```
for subj in 02 04 05 06 08 09 10 11 15 16 20 21 25 26 27; do
	echo "Zipping participant $subj"
for session in 02;do
```

## 2.3 BIDS validation

Use the BIDS-Validator to check if the dataset is BIDS compliant.

```
docker run -ti --rm -v /Volumes/Project0245/data_exp1:/data:ro bids/validator /data
```


```{r}
library(AnalyzeFMRI)

a <- f.read.nifti.header("/Volumes/Project0245/data_exp1/sub-12/ses-01/func/sub-12_ses-01_task-tom_bold.nii")

a[["pixdim"]][5]
```


# 3. Stimulation protocols {.tabset}

Create tsv file for functional localiser

## 3.1 Theory-of-Mind localiser
Event coding (in s;  10s of fixation before movie starts; accounting for hemodynamic lag) is based on Richardson et al. 2018 - reverse correlation analyses. 
```{r}
PartlyCloudy <- data.frame(onset = c(86, 98, 120, 176, 238, 252, 300, 70, 92, 106, 136, 194, 210, 228, 262, 312), #create the events (same for every sub)
                           duration = c(4, 6, 4, 16, 6, 8, 6, 4, 2, 4, 10, 4, 12, 6, 6, 4),
                           trial_type = c(rep("mental",7), rep("pain",9)))

#exp_1
for (sub in 3:28){ #note: localisers for sub-01 and sub-02 are in ses-02
  sub <- ifelse(sub < 10, paste0("0", sub), sub)
  filename = paste("/Volumes/Project0245/data_exp1/sub-", sub, "/ses-01/func/sub-", sub, "_ses-01_task-tom_events.tsv", sep ="")
write.table(PartlyCloudy, file = filename, sep="\t", row.names = FALSE, quote = FALSE)
}
#exp_2
for (sub in 1:33){ #note: ppn22 ToM is in ses-00
  sub <- ifelse(sub < 10, paste0("0", sub), sub)
  filename = paste("/Volumes/Project0245/data_exp2/sub-", sub, "/ses-01/func/sub-", sub, "_ses-01_task-tom_events.tsv", sep ="")
write.table(PartlyCloudy, file = filename, sep="\t", row.names = FALSE, quote = FALSE)
}
#exp_3
for (sub in 1:10){ #note: ppn22 ToM is in ses-00
  sub <- ifelse(sub < 10, paste0("0", sub), sub)
  filename = paste("/Volumes/Project0245/data_exp3/sub-", sub, "/ses-01/func/sub-", sub, "_ses-01_task-tom_events.tsv", sep ="")
write.table(PartlyCloudy, file = filename, sep="\t", row.names = FALSE, quote = FALSE)
}
#exp4
for (sub in 1:12){ #note: ppn22 ToM is in ses-00
  sub <- ifelse(sub < 10, paste0("0", sub), sub)
  filename = paste("/Volumes/Project0245/data_exp4/sub-", sub, "/ses-01/func/sub-", sub, "_ses-01_task-tom_events.tsv", sep ="")
write.table(PartlyCloudy, file = filename, sep="\t", row.names = FALSE, quote = FALSE)
}
```

# 4. Preprocessing {.tabset}

## 4.1 MRIQC 
MRIQC is a docker tool to do quality control of the data. More info [here](https://poldracklab.github.io/mriqc/).

MRIQC 0.14.2 was used:

```{bash}
docker run -it --rm -v /Volumes/Project0245/data_exp2/:/data:ro -v /Volumes/Project0245/data_exp2/derivatives/mriqc:/out poldracklab/mriqc:latest /data /out participant --participant-label 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 -m T1w bold --ica --fft-spikes-detector
```

Run it seperately for exp 1-4. Change participant to group to create the group reports.

## 4.2 fMRIprep 
fMRIprep is a docker tool for preprocessing of the fMRI data. More info [here](https://fmriprep.readthedocs.io/en/stable/#)

fMRIprep version 1.3.2 was used on the grid.

If you run into memory problems you can use --skip_bids_validation; skipped the --write-graph flag to save space

If run on the lab iMac, with 50GB of docker memory, and with --fs-no-reconall (no segmentation), it takes about X per participant.

```{bash}
singularity run --cleanenv /analyse/Project0245/my_images/fmriprep-1.3.2.simg /Volumes/Project0245/data_exp2/ //Volumes/Project0245/data_exp2/derivatives participant --participant-label sub-01 sub-02 sub-03 sub-04 sub-05 --fs-license-file /analyse/Project0245/my_images/license.txt --skip_bids_validation --fs-no-reconall --use-syn-sdc --use-aroma
```



Run it seperately for exp 1-4.

## 4.3 GLMdenoise 

GLMdenoise is an automated technique for denoising task-based fMRI data. It outperforms other [denoising methods](https://www.frontiersin.org/articles/10.3389/fnins.2013.00247/full) and improves the [MVPA analyses](https://www.sciencedirect.com/science/article/pii/S1053811918307626). More info [here](https://github.com/kendrickkay/GLMdenoise) and [here](https://github.com/Charestlab/pyGLMdenoise).
